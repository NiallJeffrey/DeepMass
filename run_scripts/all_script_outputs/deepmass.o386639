[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-debugdump'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-persistenced'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-control'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-server'
[0m/home/ucapnje
/home/ucapnje/share/DeepMass/run_scripts
loading mask 

(256, 256)
Loading input data
847.5560455322266
Loading clean data
917.4370486736298
Test loss = 0.0013145871
Test pearson = (0.18982396, 0.0)
2019-07-15 10:02:42.755362: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-15 10:02:43.984558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:3b:00.0
totalMemory: 15.75GiB freeMemory: 15.44GiB
2019-07-15 10:02:43.984694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-07-15 10:02:47.244538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-15 10:02:47.244603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-07-15 10:02:47.244612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-07-15 10:02:47.244771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14941 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
Plotting data. Saving to: ../outputs/picola_script_outputs/picola_data.png
<generator object batch_generator at 0x2b1933dd9ba0>
(368684, 256, 256, 1)
(8000, 256, 256, 1)
11521
unet simplest deeeper lr = 0.0003
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 256, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 128, 128, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 64, 64, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 64, 64)   18496       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 32, 32, 64)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 16, 16, 64)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 64)   36928       average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_4[0][0]      
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 64)   73792       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 64)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           batch_normalization_3[0][0]      
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 64, 64)   73792       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 96) 0           batch_normalization_2[0][0]      
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 128, 128, 96) 384         concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 128, 32) 27680       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 32) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 256, 256, 48) 0           batch_normalization_1[0][0]      
                                                                 up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 256, 256, 48) 192         concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 256, 256, 16) 6928        batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 256, 256, 1)  17          conv2d_9[0][0]                   
==================================================================================================
Total params: 281,665
Trainable params: 280,513
Non-trainable params: 1,152
__________________________________________________________________________________________________
20 32 0.0003
Epoch 1/20
 - 1160s - loss: 9.2697e-05 - val_loss: 6.2281e-05
Epoch 2/20
 - 1153s - loss: 5.0163e-05 - val_loss: 5.0027e-05
Epoch 3/20
 - 1154s - loss: 4.9600e-05 - val_loss: 5.4766e-05
Epoch 4/20
 - 1155s - loss: 4.9113e-05 - val_loss: 5.0413e-05
Epoch 5/20
 - 1154s - loss: 4.8964e-05 - val_loss: 4.9174e-05
Epoch 6/20
 - 1153s - loss: 4.8863e-05 - val_loss: 4.8883e-05
Epoch 7/20
 - 1154s - loss: 4.8724e-05 - val_loss: 5.0359e-05
Epoch 8/20
 - 1153s - loss: 4.8608e-05 - val_loss: 5.0980e-05
Epoch 9/20
 - 1153s - loss: 4.8552e-05 - val_loss: 4.9508e-05
Epoch 10/20
 - 1152s - loss: 4.8483e-05 - val_loss: 4.8897e-05
Epoch 11/20
 - 1153s - loss: 4.8426e-05 - val_loss: 4.8745e-05
Epoch 12/20
 - 1153s - loss: 4.8342e-05 - val_loss: 4.8577e-05
Epoch 13/20
 - 1154s - loss: 4.8346e-05 - val_loss: 4.8771e-05
Epoch 14/20
 - 1154s - loss: 4.8264e-05 - val_loss: 4.8854e-05
Epoch 15/20
 - 1153s - loss: 4.8307e-05 - val_loss: 4.8664e-05
Epoch 16/20
 - 1153s - loss: 4.8294e-05 - val_loss: 4.8653e-05
Epoch 17/20
 - 1153s - loss: 4.8237e-05 - val_loss: 4.8507e-05
