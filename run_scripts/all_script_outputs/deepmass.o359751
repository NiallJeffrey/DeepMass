[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-debugdump'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-persistenced'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-control'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-server'
[0m/home/ucapnje
/home/ucapnje/share/DeepMass/run_scripts
loading mask 

(256, 256)
loading noisy/input data
loaded first file: /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data00/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data01/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data02/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data03/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data04/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data05/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data06/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data07/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data08/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data09/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data10/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data11/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data12/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data13/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data14/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data15/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data16/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data17/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data18/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data19/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data20/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data21/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data22/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data23/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data24/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data25/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data26/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data27/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data28/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data29/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data30/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data31/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data32/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data33/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data34/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data35/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data36/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data37/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data38/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data39/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data40/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data41/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data42/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data43/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data44/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data45/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data46/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data47/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data48/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data49/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data50/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data51/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data52/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data53/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data54/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data55/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data56/sv_training_wiener.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data57/sv_training_wiener.npy
336.74652314186096

Apply mask
complete 15.759368419647217s 


Test loaded files
complete 11.144941091537476s 


Number of bad files = 840


Shuffle and take fraction of test data
Number of pixels sample = 262144000
pixels out of range (input/noisy) = 0
noisy array bytes = 98608087040

Rescaling
complete 98.40515565872192s 

Saving test array
1.1909537315368652
Saving train array
176.74363923072815
Deleted arrays from memory
Garbage collect: 184
loading data:
loaded first file: /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data00/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data01/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data02/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data03/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data04/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data05/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data06/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data07/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data08/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data09/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data10/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data11/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data12/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data13/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data14/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data15/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data16/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data17/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data18/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data19/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data20/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data21/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data22/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data23/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data24/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data25/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data26/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data27/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data28/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data29/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data30/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data31/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data32/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data33/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data34/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data35/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data36/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data37/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data38/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data39/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data40/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data41/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data42/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data43/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data44/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data45/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data46/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data47/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data48/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data49/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data50/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data51/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data52/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data53/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data54/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data55/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data56/sv_training_kappa_true.npy
Loading /home/ucapnje/share/DeepMass/run_scripts/../picola_training/nicaea_rescaled_nongauss_noise/training_data57/sv_training_kappa_true.npy
2070.2732849121094

Apply mask

Shuffle and take fraction of test data
Number of pixels sample = 262144000
pixels out of range (clean) = 2189
clean array bytes = 98608087040
Reloading noisy data
Test loss = 0.000466728
Test pearson = (0.34112898, 0.0)
2019-06-25 19:34:32.366384: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-06-25 19:34:34.127485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:3b:00.0
totalMemory: 15.75GiB freeMemory: 15.44GiB
2019-06-25 19:34:34.127619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-06-25 19:34:37.382197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-25 19:34:37.382266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-06-25 19:34:37.382275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-06-25 19:34:37.382448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14941 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
Plotting data. Saving to: ../outputs/picola_script_outputs/picola_data.png
<generator object batch_generator at 0x2b2b670158e0>
(368160, 256, 256, 1)
(8000, 256, 256, 1)
11505
training network wiener (no dropout) 


simple lr = 1e-05
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 1)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 256, 256, 32)      320       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
batch_normalization_1 (Batch (None, 256, 256, 32)      128       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
batch_normalization_2 (Batch (None, 256, 256, 32)      128       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 256, 256, 1)       289       
=================================================================
Total params: 28,609
Trainable params: 28,481
Non-trainable params: 128
_________________________________________________________________
20 32 1e-05
Epoch 1/20
 - 1076s - loss: 8.9822e-04 - val_loss: 4.5850e-04
Epoch 2/20
 - 1069s - loss: 4.4236e-04 - val_loss: 4.4055e-04
Epoch 3/20
 - 1070s - loss: 4.3621e-04 - val_loss: 4.3864e-04
Epoch 4/20
 - 1070s - loss: 4.3545e-04 - val_loss: 4.4117e-04
Epoch 5/20
 - 1070s - loss: 4.3511e-04 - val_loss: 4.4124e-04
Epoch 6/20
 - 1069s - loss: 4.3563e-04 - val_loss: 4.3784e-04
Epoch 7/20
 - 1070s - loss: 4.3505e-04 - val_loss: 4.4182e-04
Epoch 8/20
 - 1069s - loss: 4.3516e-04 - val_loss: 4.3519e-04
Epoch 9/20
 - 1070s - loss: 4.3501e-04 - val_loss: 4.4364e-04
Epoch 10/20
 - 1069s - loss: 4.3459e-04 - val_loss: 4.4099e-04
Epoch 11/20
 - 1070s - loss: 4.3437e-04 - val_loss: 4.4192e-04
Epoch 12/20
 - 1069s - loss: 4.3477e-04 - val_loss: 4.3410e-04
Epoch 13/20
 - 1069s - loss: 4.3435e-04 - val_loss: 4.3534e-04
Epoch 14/20
 - 1070s - loss: 4.3441e-04 - val_loss: 4.3717e-04
Epoch 15/20
 - 1070s - loss: 4.3412e-04 - val_loss: 4.4025e-04
Epoch 16/20
 - 1070s - loss: 4.3406e-04 - val_loss: 4.4025e-04
Epoch 17/20
 - 1070s - loss: 4.3461e-04 - val_loss: 4.4153e-04
Epoch 18/20
 - 1070s - loss: 4.3416e-04 - val_loss: 4.3342e-04
Epoch 19/20
 - 1069s - loss: 4.3469e-04 - val_loss: 4.3701e-04
Epoch 20/20
 - 1070s - loss: 4.3425e-04 - val_loss: 4.3851e-04
Saving losses
Save network
Predict results
Test loss = 0.000466728
Test pearson = (0.34112898, 0.0)
Result loss = 0.0004363408
Result pearson = (0.37016135, 0.0)
Garbage collect: 13964

simple lr = 3e-06
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 256, 256, 1)       0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 256, 256, 32)      320       
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
batch_normalization_3 (Batch (None, 256, 256, 32)      128       
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 256, 256, 32)      9248      
_________________________________________________________________
batch_normalization_4 (Batch (None, 256, 256, 32)      128       
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 256, 256, 1)       289       
=================================================================
Total params: 28,609
Trainable params: 28,481
Non-trainable params: 128
_________________________________________________________________
20 32 3e-06
Epoch 1/20
 - 1072s - loss: 0.0022 - val_loss: 4.9706e-04
Epoch 2/20
 - 1072s - loss: 4.4399e-04 - val_loss: 4.4442e-04
Epoch 3/20
 - 1072s - loss: 4.3671e-04 - val_loss: 4.4338e-04
Epoch 4/20
 - 1072s - loss: 4.3645e-04 - val_loss: 4.5160e-04
Epoch 5/20
 - 1071s - loss: 4.3564e-04 - val_loss: 4.4153e-04
Epoch 6/20
 - 1074s - loss: 4.3590e-04 - val_loss: 4.3930e-04
Epoch 7/20
 - 1071s - loss: 4.3517e-04 - val_loss: 4.3626e-04
Epoch 8/20
 - 1071s - loss: 4.3535e-04 - val_loss: 4.4034e-04
Epoch 9/20
 - 1070s - loss: 4.3517e-04 - val_loss: 4.5061e-04
Epoch 10/20
 - 1072s - loss: 4.3484e-04 - val_loss: 4.3816e-04
Epoch 11/20
 - 1072s - loss: 4.3472e-04 - val_loss: 4.7272e-04
Epoch 12/20
 - 1072s - loss: 4.3482e-04 - val_loss: 4.4504e-04
Epoch 13/20
 - 1072s - loss: 4.3479e-04 - val_loss: 4.5444e-04
Epoch 14/20
 - 1073s - loss: 4.3472e-04 - val_loss: 4.3373e-04
Epoch 15/20
 - 1072s - loss: 4.3418e-04 - val_loss: 4.3248e-04
Epoch 16/20
 - 1071s - loss: 4.3486e-04 - val_loss: 4.3631e-04
Epoch 17/20
 - 1071s - loss: 4.3490e-04 - val_loss: 4.3724e-04
Epoch 18/20
 - 1072s - loss: 4.3491e-04 - val_loss: 4.5621e-04
Epoch 19/20
 - 1072s - loss: 4.3503e-04 - val_loss: 4.4051e-04
Epoch 20/20
 - 1073s - loss: 4.3440e-04 - val_loss: 4.4049e-04
Saving losses
Save network
Predict results
Test loss = 0.000466728
Test pearson = (0.34112898, 0.0)
Result loss = 0.00043997378
Result pearson = (0.3688838, 0.0)
Garbage collect: 16034

unet deep lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 256, 256, 32) 320         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 256, 256, 32) 128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 128, 64) 256         conv2d_12[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_13[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 32, 32, 128)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 128)  147584      average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_7[0][0]      
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 64, 64, 256)  1024        concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 64, 64, 64)   147520      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_6[0][0]      
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 128, 128, 128 512         concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 128, 128, 64) 73792       batch_normalization_10[0][0]     
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_5[0][0]      
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 256, 256, 96) 384         concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 32) 27680       batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 1)  33          conv2d_17[0][0]                  
==================================================================================================
Total params: 492,609
Trainable params: 490,945
Non-trainable params: 1,664
__________________________________________________________________________________________________
20 32 1e-05
Epoch 1/20
 - 1805s - loss: 0.0011 - val_loss: 4.4159e-04
Epoch 2/20
 - 1798s - loss: 4.3982e-04 - val_loss: 4.4233e-04
Epoch 3/20
 - 1800s - loss: 4.3742e-04 - val_loss: 4.4468e-04
Epoch 4/20
 - 1799s - loss: 4.3680e-04 - val_loss: 4.4258e-04
Epoch 5/20
 - 1799s - loss: 4.3635e-04 - val_loss: 4.3677e-04
Epoch 6/20
 - 1800s - loss: 4.3672e-04 - val_loss: 4.3506e-04
Epoch 7/20
 - 1800s - loss: 4.3546e-04 - val_loss: 4.3844e-04
Epoch 8/20
 - 1801s - loss: 4.3563e-04 - val_loss: 4.3592e-04
Epoch 9/20
 - 1800s - loss: 4.3513e-04 - val_loss: 4.3497e-04
Epoch 10/20
 - 1799s - loss: 4.3577e-04 - val_loss: 4.3979e-04
Epoch 11/20
 - 1799s - loss: 4.3476e-04 - val_loss: 4.3618e-04
Epoch 12/20
 - 1800s - loss: 4.3467e-04 - val_loss: 4.3502e-04
Epoch 13/20
 - 1800s - loss: 4.3480e-04 - val_loss: 4.3320e-04
Epoch 14/20
 - 1800s - loss: 4.3456e-04 - val_loss: 4.3451e-04
Epoch 15/20
 - 1800s - loss: 4.3431e-04 - val_loss: 4.3853e-04
Epoch 16/20
 - 1801s - loss: 4.3466e-04 - val_loss: 4.3989e-04
Epoch 17/20
 - 1800s - loss: 4.3467e-04 - val_loss: 4.3711e-04
Epoch 18/20
 - 1799s - loss: 4.3548e-04 - val_loss: 4.3582e-04
Epoch 19/20
 - 1800s - loss: 4.3399e-04 - val_loss: 4.3199e-04
Epoch 20/20
 - 1799s - loss: 4.3425e-04 - val_loss: 4.3532e-04
Saving losses
Save network
Test loss = 0.000466728
Test pearson = (0.34112898, 0.0)
Result loss = 0.00043666715
Result pearson = (0.37077746, 0.0)
Garbage collect: 36418

unet deep lr = 3e-06
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 256, 256, 32) 320         input_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 256, 256, 32) 128         conv2d_19[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 32, 32, 128)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 128)  147584      average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 128)  512         conv2d_22[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_14[0][0]     
                                                                 up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 64, 64, 256)  1024        concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 64, 64)   147520      batch_normalization_16[0][0]     
__________________________________________________________________________________________________
up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_23[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_13[0][0]     
                                                                 up_sampling2d_5[0][0]            
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 128, 128, 128 512         concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 128, 128, 64) 73792       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_24[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_12[0][0]     
                                                                 up_sampling2d_6[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 256, 256, 96) 384         concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 256, 256, 32) 27680       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 256, 256, 1)  33          conv2d_25[0][0]                  
==================================================================================================
Total params: 492,609
Trainable params: 490,945
Non-trainable params: 1,664
__________________________________________________________________________________________________
20 32 3e-06
Epoch 1/20
 - 1809s - loss: 0.0029 - val_loss: 0.0014
Epoch 2/20
 - 1806s - loss: 0.0012 - val_loss: 4.5037e-04
Epoch 3/20
 - 1806s - loss: 4.4532e-04 - val_loss: 4.5061e-04
Epoch 4/20
 - 1806s - loss: 4.3953e-04 - val_loss: 4.4329e-04
Epoch 5/20
 - 1807s - loss: 4.3829e-04 - val_loss: 4.4249e-04
Epoch 6/20
 - 1806s - loss: 4.3860e-04 - val_loss: 4.3960e-04
Epoch 7/20
 - 1806s - loss: 4.3790e-04 - val_loss: 4.3772e-04
Epoch 8/20
 - 1806s - loss: 4.3718e-04 - val_loss: 4.3675e-04
Epoch 9/20
 - 1806s - loss: 4.3742e-04 - val_loss: 4.3794e-04
Epoch 10/20
 - 1807s - loss: 4.3698e-04 - val_loss: 4.3678e-04
Epoch 11/20
 - 1806s - loss: 4.3648e-04 - val_loss: 4.3637e-04
Epoch 12/20
 - 1806s - loss: 4.3649e-04 - val_loss: 4.3605e-04
Epoch 13/20
 - 1806s - loss: 4.3554e-04 - val_loss: 4.3831e-04
Epoch 14/20
 - 1806s - loss: 4.3597e-04 - val_loss: 4.3774e-04
Epoch 15/20
 - 1806s - loss: 4.3597e-04 - val_loss: 4.4213e-04
Epoch 16/20
 - 1806s - loss: 4.3553e-04 - val_loss: 4.3655e-04
Epoch 17/20
 - 1806s - loss: 4.3575e-04 - val_loss: 4.3652e-04
Epoch 18/20
 - 1806s - loss: 4.3571e-04 - val_loss: 4.3411e-04
Epoch 19/20
 - 1806s - loss: 4.3581e-04 - val_loss: 4.3579e-04
Epoch 20/20
 - 1806s - loss: 4.3623e-04 - val_loss: 4.3926e-04
Saving losses
Save network
Test loss = 0.000466728
Test pearson = (0.34112898, 0.0)
Result loss = 0.00043758863
Result pearson = (0.367972, 0.0)
Garbage collect: 36418
Using TensorFlow backend.
