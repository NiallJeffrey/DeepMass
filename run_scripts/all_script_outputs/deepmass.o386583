[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-debugdump'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-persistenced'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-control'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-server'
[0m/home/ucapnje
/home/ucapnje/share/DeepMass/run_scripts
loading mask 

(256, 256)
Loading input data
849.5058348178864
Loading clean data
896.8281717300415
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
2019-07-11 21:01:27.898687: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-11 21:01:29.046339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:3b:00.0
totalMemory: 15.75GiB freeMemory: 15.44GiB
2019-07-11 21:01:29.046446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-07-11 21:01:32.258980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 21:01:32.259042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-07-11 21:01:32.259051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-07-11 21:01:32.259223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14941 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
Plotting data. Saving to: ../outputs/picola_script_outputs/picola_data.png
<generator object batch_generator at 0x2b3a1e5c3db0>
(368684, 256, 256, 1)
(8000, 256, 256, 1)
11521
unet simplest deeeper lr = None
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 256, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 128, 128, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 64, 64, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 64, 64)   18496       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 32, 32, 64)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 16, 16, 64)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 64)   36928       average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_4[0][0]      
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 64)   73792       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 64)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           batch_normalization_3[0][0]      
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 64, 64)   73792       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 96) 0           batch_normalization_2[0][0]      
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 128, 128, 96) 384         concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 128, 32) 27680       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 32) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 256, 256, 48) 0           batch_normalization_1[0][0]      
                                                                 up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 256, 256, 48) 192         concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 256, 256, 16) 6928        batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 256, 256, 1)  17          conv2d_9[0][0]                   
==================================================================================================
Total params: 281,665
Trainable params: 280,513
Non-trainable params: 1,152
__________________________________________________________________________________________________
20 32 None
Epoch 1/20
 - 1151s - loss: 4.5776e-04 - val_loss: 4.4063e-04
Epoch 2/20
 - 1144s - loss: 4.2464e-04 - val_loss: 4.5385e-04
Epoch 3/20
 - 1142s - loss: 4.2220e-04 - val_loss: 4.3331e-04
Epoch 4/20
 - 1143s - loss: 4.2286e-04 - val_loss: 4.5643e-04
Epoch 5/20
 - 1144s - loss: 4.2223e-04 - val_loss: 5.6471e-04
Epoch 6/20
 - 1143s - loss: 4.2132e-04 - val_loss: 6.9927e-04
Epoch 7/20
 - 1143s - loss: 4.2084e-04 - val_loss: 5.0734e-04
Epoch 8/20
 - 1144s - loss: 4.2229e-04 - val_loss: 5.5655e-04
Epoch 9/20
 - 1142s - loss: 4.2141e-04 - val_loss: 5.2198e-04
Epoch 10/20
 - 1143s - loss: 4.2122e-04 - val_loss: 4.8338e-04
Epoch 11/20
 - 1143s - loss: 4.2122e-04 - val_loss: 5.1311e-04
Epoch 12/20
 - 1144s - loss: 4.2102e-04 - val_loss: 4.7135e-04
Epoch 13/20
 - 1144s - loss: 4.2179e-04 - val_loss: 5.4062e-04
Epoch 14/20
 - 1144s - loss: 4.2114e-04 - val_loss: 5.7865e-04
Epoch 15/20
 - 1143s - loss: 4.2135e-04 - val_loss: 4.8617e-04
Epoch 16/20
 - 1144s - loss: 4.2108e-04 - val_loss: 0.0010
Epoch 17/20
 - 1143s - loss: 4.2080e-04 - val_loss: 5.2511e-04
Epoch 18/20
 - 1143s - loss: 4.2153e-04 - val_loss: 5.3106e-04
Epoch 19/20
 - 1144s - loss: 4.2066e-04 - val_loss: 4.9261e-04
Epoch 20/20
 - 1144s - loss: 4.2106e-04 - val_loss: 5.1150e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.00050993223
Result pearson = (0.34116885, 0.0)
Garbage collect: 0
unet simplest deeeper lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 256, 256, 16) 160         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 256, 256, 16) 64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 128, 128, 16) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 128, 128, 32) 4640        average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 128, 128, 32) 128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 64, 64, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 64, 64)   18496       average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 32, 32, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 16, 16, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_13[0][0]     
                                                                 up_sampling2d_5[0][0]            
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 64)   256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 64, 64, 128)  0           batch_normalization_12[0][0]     
                                                                 up_sampling2d_6[0][0]            
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 64, 64, 64)   73792       batch_normalization_16[0][0]     
__________________________________________________________________________________________________
up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 128, 96) 0           batch_normalization_11[0][0]     
                                                                 up_sampling2d_7[0][0]            
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 128, 128, 96) 384         concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 128, 128, 32) 27680       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 32) 0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 256, 256, 48) 0           batch_normalization_10[0][0]     
                                                                 up_sampling2d_8[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 256, 256, 48) 192         concatenate_8[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 256, 256, 16) 6928        batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 256, 256, 1)  17          conv2d_19[0][0]                  
==================================================================================================
Total params: 281,665
Trainable params: 280,513
Non-trainable params: 1,152
__________________________________________________________________________________________________
20 32 1e-05
Epoch 1/20
 - 1154s - loss: 7.4267e-04 - val_loss: 4.5118e-04
Epoch 2/20
 - 1150s - loss: 4.3486e-04 - val_loss: 4.3604e-04
Epoch 3/20
 - 1153s - loss: 4.3003e-04 - val_loss: 4.3341e-04
Epoch 4/20
 - 1153s - loss: 4.2879e-04 - val_loss: 4.3139e-04
Epoch 5/20
 - 1152s - loss: 4.2813e-04 - val_loss: 4.2915e-04
Epoch 6/20
 - 1152s - loss: 4.2751e-04 - val_loss: 4.3440e-04
Epoch 7/20
 - 1151s - loss: 4.2735e-04 - val_loss: 4.3112e-04
Epoch 8/20
 - 1152s - loss: 4.2671e-04 - val_loss: 4.3259e-04
Epoch 9/20
 - 1151s - loss: 4.2711e-04 - val_loss: 4.2972e-04
Epoch 10/20
 - 1153s - loss: 4.2619e-04 - val_loss: 4.2607e-04
Epoch 11/20
 - 1152s - loss: 4.2487e-04 - val_loss: 4.3158e-04
Epoch 12/20
 - 1152s - loss: 4.2556e-04 - val_loss: 4.3032e-04
Epoch 13/20
 - 1152s - loss: 4.2552e-04 - val_loss: 4.2787e-04
Epoch 14/20
 - 1152s - loss: 4.2555e-04 - val_loss: 4.2467e-04
Epoch 15/20
 - 1152s - loss: 4.2528e-04 - val_loss: 4.3040e-04
Epoch 16/20
 - 1153s - loss: 4.2548e-04 - val_loss: 4.2777e-04
Epoch 17/20
 - 1152s - loss: 4.2475e-04 - val_loss: 4.2679e-04
Epoch 18/20
 - 1151s - loss: 4.2501e-04 - val_loss: 4.2346e-04
Epoch 19/20
 - 1152s - loss: 4.2462e-04 - val_loss: 4.2768e-04
Epoch 20/20
 - 1152s - loss: 4.2458e-04 - val_loss: 4.2553e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.00042692025
Result pearson = (0.38555148, 0.0)
Garbage collect: 42074
unet simplest deeeper lr = 3e-06
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 256, 256, 16) 160         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 256, 256, 16) 64          conv2d_21[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 128, 128, 16) 0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 128, 128, 32) 4640        average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 128, 128, 32) 128         conv2d_22[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 64, 64, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 64, 64)   18496       average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 32, 32, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 32, 32, 64)   36928       average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         conv2d_24[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 16, 16, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 64)   36928       average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 64)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_22[0][0]     
                                                                 up_sampling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_10 (UpSampling2D) (None, 64, 64, 64)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 64, 64, 128)  0           batch_normalization_21[0][0]     
                                                                 up_sampling2d_10[0][0]           
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 64, 64, 128)  512         concatenate_10[0][0]             
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 64, 64, 64)   73792       batch_normalization_25[0][0]     
__________________________________________________________________________________________________
up_sampling2d_11 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_27[0][0]                  
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 128, 128, 96) 0           batch_normalization_20[0][0]     
                                                                 up_sampling2d_11[0][0]           
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 128, 128, 96) 384         concatenate_11[0][0]             
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 128, 128, 32) 27680       batch_normalization_26[0][0]     
__________________________________________________________________________________________________
up_sampling2d_12 (UpSampling2D) (None, 256, 256, 32) 0           conv2d_28[0][0]                  
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 256, 256, 48) 0           batch_normalization_19[0][0]     
                                                                 up_sampling2d_12[0][0]           
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 256, 256, 48) 192         concatenate_12[0][0]             
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 256, 256, 16) 6928        batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 256, 256, 1)  17          conv2d_29[0][0]                  
==================================================================================================
Total params: 281,665
Trainable params: 280,513
Non-trainable params: 1,152
__________________________________________________________________________________________________
20 32 3e-06
Epoch 1/20
 - 1140s - loss: 0.0013 - val_loss: 4.6404e-04
Epoch 2/20
 - 1136s - loss: 4.4397e-04 - val_loss: 4.3931e-04
Epoch 3/20
 - 1137s - loss: 4.3815e-04 - val_loss: 4.3595e-04
Epoch 4/20
 - 1137s - loss: 4.3534e-04 - val_loss: 4.3829e-04
Epoch 5/20
 - 1136s - loss: 4.3404e-04 - val_loss: 4.3319e-04
Epoch 6/20
 - 1136s - loss: 4.3314e-04 - val_loss: 4.3877e-04
Epoch 7/20
 - 1137s - loss: 4.3259e-04 - val_loss: 4.3470e-04
Epoch 8/20
 - 1137s - loss: 4.3254e-04 - val_loss: 4.3698e-04
Epoch 9/20
 - 1137s - loss: 4.3248e-04 - val_loss: 4.3213e-04
Epoch 10/20
 - 1136s - loss: 4.3185e-04 - val_loss: 4.3851e-04
Epoch 11/20
 - 1136s - loss: 4.3151e-04 - val_loss: 4.3618e-04
Epoch 12/20
 - 1135s - loss: 4.3133e-04 - val_loss: 4.3534e-04
Epoch 13/20
 - 1137s - loss: 4.3053e-04 - val_loss: 4.3362e-04
Epoch 14/20
 - 1137s - loss: 4.2997e-04 - val_loss: 4.3251e-04
Epoch 15/20
 - 1137s - loss: 4.3087e-04 - val_loss: 4.3180e-04
Epoch 16/20
 - 1137s - loss: 4.3053e-04 - val_loss: 4.3208e-04
Epoch 17/20
 - 1136s - loss: 4.3019e-04 - val_loss: 4.3104e-04
Epoch 18/20
 - 1135s - loss: 4.3020e-04 - val_loss: 4.2894e-04
Epoch 19/20
 - 1136s - loss: 4.3033e-04 - val_loss: 4.3232e-04
Epoch 20/20
 - 1137s - loss: 4.2987e-04 - val_loss: 4.2774e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.00043209907
Result pearson = (0.37202424, 0.0)
Garbage collect: 42074
unet deeeper lr = None
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 256, 256, 16) 160         input_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 256, 256, 16) 64          conv2d_31[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 128, 128, 16) 0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 128, 128, 32) 4640        average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 128, 128, 32) 128         conv2d_32[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 64, 64, 32)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 64, 64, 64)   18496       average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_33[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 32, 32, 64)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 32, 32, 128)  73856       average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 32, 32, 128)  512         conv2d_34[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 16, 16, 128)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 256)  295168      average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 256)  1024        conv2d_35[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_13 (UpSampling2D) (None, 32, 32, 256)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 32, 32, 384)  0           batch_normalization_31[0][0]     
                                                                 up_sampling2d_13[0][0]           
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 32, 32, 128)  512         conv2d_36[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_14 (UpSampling2D) (None, 64, 64, 128)  0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 64, 64, 192)  0           batch_normalization_30[0][0]     
                                                                 up_sampling2d_14[0][0]           
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 64, 64, 192)  768         concatenate_14[0][0]             
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 64, 64, 64)   110656      batch_normalization_34[0][0]     
__________________________________________________________________________________________________
up_sampling2d_15 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_37[0][0]                  
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 128, 128, 96) 0           batch_normalization_29[0][0]     
                                                                 up_sampling2d_15[0][0]           
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 128, 128, 96) 384         concatenate_15[0][0]             
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 128, 128, 32) 27680       batch_normalization_35[0][0]     
__________________________________________________________________________________________________
up_sampling2d_16 (UpSampling2D) (None, 256, 256, 32) 0           conv2d_38[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 256, 256, 48) 0           batch_normalization_28[0][0]     
                                                                 up_sampling2d_16[0][0]           
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 256, 256, 48) 192         concatenate_16[0][0]             
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 256, 256, 16) 6928        batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 256, 256, 1)  17          conv2d_39[0][0]                  
==================================================================================================
Total params: 983,937
Trainable params: 982,017
Non-trainable params: 1,920
__________________________________________________________________________________________________
20 32 None
Epoch 1/20
 - 1231s - loss: 4.5733e-04 - val_loss: 6.5449e-04
Epoch 2/20
 - 1227s - loss: 4.2378e-04 - val_loss: 4.2763e-04
Epoch 3/20
 - 1228s - loss: 4.2245e-04 - val_loss: 4.4427e-04
Epoch 4/20
 - 1227s - loss: 4.2209e-04 - val_loss: 5.9154e-04
Epoch 5/20
 - 1227s - loss: 4.2224e-04 - val_loss: 4.5400e-04
Epoch 6/20
 - 1228s - loss: 4.2155e-04 - val_loss: 4.4908e-04
Epoch 7/20
 - 1228s - loss: 4.2178e-04 - val_loss: 4.4783e-04
Epoch 8/20
 - 1228s - loss: 4.2125e-04 - val_loss: 5.0413e-04
Epoch 9/20
 - 1228s - loss: 4.2058e-04 - val_loss: 6.9755e-04
Epoch 10/20
 - 1229s - loss: 4.2111e-04 - val_loss: 6.4905e-04
Epoch 11/20
 - 1228s - loss: 4.2118e-04 - val_loss: 5.4585e-04
Epoch 12/20
 - 1228s - loss: 4.2154e-04 - val_loss: 0.0010
Epoch 13/20
 - 1228s - loss: 4.2031e-04 - val_loss: 4.5920e-04
Epoch 14/20
 - 1228s - loss: 4.2084e-04 - val_loss: 4.6465e-04
Epoch 15/20
 - 1228s - loss: 4.2115e-04 - val_loss: 8.4805e-04
Epoch 16/20
 - 1229s - loss: 4.2071e-04 - val_loss: 4.8488e-04
Epoch 17/20
 - 1229s - loss: 4.2097e-04 - val_loss: 5.3353e-04
Epoch 18/20
 - 1227s - loss: 4.2074e-04 - val_loss: 5.2810e-04
Epoch 19/20
 - 1226s - loss: 4.2045e-04 - val_loss: 4.8080e-04
Epoch 20/20
 - 1229s - loss: 4.2029e-04 - val_loss: 6.0560e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.0006077229
Result pearson = (0.309351, 0.0)
Garbage collect: 41856
unet deeeper lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 256, 256, 16) 160         input_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 256, 256, 16) 64          conv2d_41[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 128, 128, 16) 0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 128, 128, 32) 4640        average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 128, 128, 32) 128         conv2d_42[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 64, 64, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 64, 64, 64)   18496       average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 64, 64, 64)   256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 32, 32, 64)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 32, 32, 128)  73856       average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 32, 32, 128)  512         conv2d_44[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 16, 16, 128)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 16, 16, 256)  295168      average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 256)  1024        conv2d_45[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_17 (UpSampling2D) (None, 32, 32, 256)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 32, 32, 384)  0           batch_normalization_40[0][0]     
                                                                 up_sampling2d_17[0][0]           
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 32, 32, 128)  512         conv2d_46[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_18 (UpSampling2D) (None, 64, 64, 128)  0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 64, 64, 192)  0           batch_normalization_39[0][0]     
                                                                 up_sampling2d_18[0][0]           
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 64, 64, 192)  768         concatenate_18[0][0]             
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 64, 64, 64)   110656      batch_normalization_43[0][0]     
__________________________________________________________________________________________________
up_sampling2d_19 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_47[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 128, 128, 96) 0           batch_normalization_38[0][0]     
                                                                 up_sampling2d_19[0][0]           
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 128, 128, 96) 384         concatenate_19[0][0]             
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 128, 128, 32) 27680       batch_normalization_44[0][0]     
__________________________________________________________________________________________________
up_sampling2d_20 (UpSampling2D) (None, 256, 256, 32) 0           conv2d_48[0][0]                  
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 256, 256, 48) 0           batch_normalization_37[0][0]     
                                                                 up_sampling2d_20[0][0]           
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 256, 256, 48) 192         concatenate_20[0][0]             
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 256, 256, 16) 6928        batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 256, 256, 1)  17          conv2d_49[0][0]                  
==================================================================================================
Total params: 983,937
Trainable params: 982,017
Non-trainable params: 1,920
__________________________________________________________________________________________________
20 32 1e-05
Epoch 1/20
 - 1230s - loss: 7.7285e-04 - val_loss: 4.6003e-04
Epoch 2/20
 - 1229s - loss: 4.3569e-04 - val_loss: 4.2940e-04
Epoch 3/20
 - 1228s - loss: 4.3016e-04 - val_loss: 4.3231e-04
Epoch 4/20
 - 1229s - loss: 4.2919e-04 - val_loss: 4.3199e-04
Epoch 5/20
 - 1228s - loss: 4.2756e-04 - val_loss: 4.3093e-04
Epoch 6/20
 - 1229s - loss: 4.2675e-04 - val_loss: 4.2674e-04
Epoch 7/20
 - 1228s - loss: 4.2654e-04 - val_loss: 4.2955e-04
Epoch 8/20
 - 1228s - loss: 4.2563e-04 - val_loss: 4.2501e-04
Epoch 9/20
 - 1229s - loss: 4.2487e-04 - val_loss: 4.2939e-04
Epoch 10/20
 - 1228s - loss: 4.2540e-04 - val_loss: 4.2634e-04
Epoch 11/20
 - 1229s - loss: 4.2489e-04 - val_loss: 4.3180e-04
Epoch 12/20
 - 1228s - loss: 4.2427e-04 - val_loss: 4.2470e-04
Epoch 13/20
 - 1228s - loss: 4.2518e-04 - val_loss: 4.2297e-04
Epoch 14/20
 - 1228s - loss: 4.2492e-04 - val_loss: 4.3561e-04
Epoch 15/20
 - 1229s - loss: 4.2500e-04 - val_loss: 4.2833e-04
Epoch 16/20
 - 1228s - loss: 4.2418e-04 - val_loss: 4.2471e-04
Epoch 17/20
 - 1229s - loss: 4.2440e-04 - val_loss: 4.3317e-04
Epoch 18/20
 - 1229s - loss: 4.2397e-04 - val_loss: 4.2611e-04
Epoch 19/20
 - 1228s - loss: 4.2400e-04 - val_loss: 4.2944e-04
Epoch 20/20
 - 1226s - loss: 4.2416e-04 - val_loss: 4.3017e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.00042870257
Result pearson = (0.3837533, 0.0)
Garbage collect: 42074
unet deeeper lr = 3e-06
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 256, 256, 16) 160         input_6[0][0]                    
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 256, 256, 16) 64          conv2d_51[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 128, 128, 16) 0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 128, 128, 32) 4640        average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 128, 128, 32) 128         conv2d_52[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 64, 64, 32)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 64, 64, 64)   18496       average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 64, 64, 64)   256         conv2d_53[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 32, 32, 64)   0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 32, 32, 128)  73856       average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 32, 32, 128)  512         conv2d_54[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_24 (AveragePo (None, 16, 16, 128)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 16, 16, 256)  295168      average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 16, 16, 256)  1024        conv2d_55[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_21 (UpSampling2D) (None, 32, 32, 256)  0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 32, 32, 384)  0           batch_normalization_49[0][0]     
                                                                 up_sampling2d_21[0][0]           
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 32, 32, 128)  512         conv2d_56[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_22 (UpSampling2D) (None, 64, 64, 128)  0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 64, 64, 192)  0           batch_normalization_48[0][0]     
                                                                 up_sampling2d_22[0][0]           
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 64, 64, 192)  768         concatenate_22[0][0]             
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 64, 64, 64)   110656      batch_normalization_52[0][0]     
__________________________________________________________________________________________________
up_sampling2d_23 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_57[0][0]                  
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 128, 128, 96) 0           batch_normalization_47[0][0]     
                                                                 up_sampling2d_23[0][0]           
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 128, 128, 96) 384         concatenate_23[0][0]             
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 128, 128, 32) 27680       batch_normalization_53[0][0]     
__________________________________________________________________________________________________
up_sampling2d_24 (UpSampling2D) (None, 256, 256, 32) 0           conv2d_58[0][0]                  
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 256, 256, 48) 0           batch_normalization_46[0][0]     
                                                                 up_sampling2d_24[0][0]           
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 256, 256, 48) 192         concatenate_24[0][0]             
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 256, 256, 16) 6928        batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 256, 256, 1)  17          conv2d_59[0][0]                  
==================================================================================================
Total params: 983,937
Trainable params: 982,017
Non-trainable params: 1,920
__________________________________________________________________________________________________
20 32 3e-06
Epoch 1/20
 - 1222s - loss: 7.9683e-04 - val_loss: 4.4599e-04
Epoch 2/20
 - 1220s - loss: 4.3810e-04 - val_loss: 4.3699e-04
Epoch 3/20
 - 1220s - loss: 4.3281e-04 - val_loss: 4.3498e-04
Epoch 4/20
 - 1218s - loss: 4.3001e-04 - val_loss: 4.2929e-04
Epoch 5/20
 - 1219s - loss: 4.2964e-04 - val_loss: 4.2660e-04
Epoch 6/20
 - 1219s - loss: 4.2895e-04 - val_loss: 4.3362e-04
Epoch 7/20
 - 1219s - loss: 4.2813e-04 - val_loss: 4.3181e-04
Epoch 8/20
 - 1219s - loss: 4.2720e-04 - val_loss: 4.3278e-04
Epoch 9/20
 - 1219s - loss: 4.2706e-04 - val_loss: 4.2801e-04
Epoch 10/20
 - 1220s - loss: 4.2668e-04 - val_loss: 4.2937e-04
Epoch 11/20
 - 1219s - loss: 4.2664e-04 - val_loss: 4.2923e-04
Epoch 12/20
 - 1220s - loss: 4.2605e-04 - val_loss: 4.3099e-04
Epoch 13/20
 - 1219s - loss: 4.2602e-04 - val_loss: 4.2610e-04
Epoch 14/20
 - 1219s - loss: 4.2560e-04 - val_loss: 4.2808e-04
Epoch 15/20
 - 1220s - loss: 4.2565e-04 - val_loss: 4.2927e-04
Epoch 16/20
 - 1219s - loss: 4.2560e-04 - val_loss: 4.2867e-04
Epoch 17/20
 - 1218s - loss: 4.2590e-04 - val_loss: 4.2953e-04
Epoch 18/20
 - 1219s - loss: 4.2540e-04 - val_loss: 4.2440e-04
Epoch 19/20
 - 1219s - loss: 4.2528e-04 - val_loss: 4.2731e-04
Epoch 20/20
 - 1219s - loss: 4.2465e-04 - val_loss: 4.2848e-04
Saving losses
Save network
Test loss = 0.0004627225
Test pearson = (0.34128594, 0.0)
Result loss = 0.00042736574
Result pearson = (0.3844298, 0.0)
Garbage collect: 41576
Using TensorFlow backend.
