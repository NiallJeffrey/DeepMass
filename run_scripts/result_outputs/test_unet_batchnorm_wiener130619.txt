[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-debugdump'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-persistenced'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-control'
[0m[33mWARNING: Non existent mount point (file) in container: '/var/singularity/mnt/final/usr/bin/nvidia-cuda-mps-server'
[0m/home/ucapnje
2019-06-13 16:18:28.703480: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-06-13 16:18:29.848335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:3b:00.0
totalMemory: 15.75GiB freeMemory: 15.44GiB
2019-06-13 16:18:29.848426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-06-13 16:18:33.507808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-13 16:18:33.507871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-06-13 16:18:33.507879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-06-13 16:18:33.508035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14941 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
/home/ucapnje/share/DeepMass/run_scripts
loading mask 

(256, 256)
loading data:
593.6853592395782
2164.4382541179657

Apply mask

Number of bad files = 503


Shuffle and take fraction of test data
Number of pixels sample = 131072000
pixels out of range (truth) = 8
pixels out of range (input/noisy) = 0
clean array bytes = 60685549568
noisy array bytes = 60685549568
Test loss = 5.1116738e-05
Plotting data. Saving to: ../outputs/picola_script_outputs/picola_data.png
<generator object batch_generator at 0x2b562c01a888>
(223497, 256, 256, 1)
(8000, 256, 256, 1)
6984
training network wiener (no dropout) 

unet_simple lr = 0.0001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 64, 128)  73856       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 128, 192 0           batch_normalization_2[0][0]      
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 128, 192 768         concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 64) 110656      batch_normalization_4[0][0]      
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_1[0][0]      
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 256, 256, 96) 384         concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 256, 256, 32) 27680       batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 256, 256, 1)  33          conv2d_5[0][0]                   
==================================================================================================
Total params: 233,089
Trainable params: 232,065
Non-trainable params: 1,024
__________________________________________________________________________________________________
10 32 0.0001
Epoch 1/10
Using TensorFlow backend.
 - 1090s - loss: 7.3093e-05 - val_loss: 5.8653e-05
Epoch 2/10
 - 1083s - loss: 4.9704e-05 - val_loss: 4.8353e-05
Epoch 3/10
 - 1083s - loss: 4.9382e-05 - val_loss: 4.8443e-05
Epoch 4/10
 - 1083s - loss: 4.9090e-05 - val_loss: 4.8631e-05
Epoch 5/10
 - 1082s - loss: 4.8913e-05 - val_loss: 4.9211e-05
Epoch 6/10
 - 1083s - loss: 4.8854e-05 - val_loss: 4.8310e-05
Epoch 7/10
 - 1083s - loss: 4.8787e-05 - val_loss: 4.8042e-05
Epoch 8/10
 - 1083s - loss: 4.8732e-05 - val_loss: 4.9157e-05
Epoch 9/10
 - 1082s - loss: 4.8714e-05 - val_loss: 4.8201e-05
Epoch 10/10
 - 1083s - loss: 4.8685e-05 - val_loss: 4.7890e-05
unet_simple lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 256, 256, 32) 320         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 256, 256, 32) 128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 128, 64) 18496       average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 64, 64, 128)  73856       average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 64, 128)  512         conv2d_9[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 192 0           batch_normalization_7[0][0]      
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 128, 128, 192 768         concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 128, 128, 64) 110656      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_6[0][0]      
                                                                 up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 256, 256, 96) 384         concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 256, 256, 32) 27680       batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 256, 256, 1)  33          conv2d_11[0][0]                  
==================================================================================================
Total params: 233,089
Trainable params: 232,065
Non-trainable params: 1,024
__________________________________________________________________________________________________
10 32 1e-05
Epoch 1/10
 - 1089s - loss: 3.0498e-04 - val_loss: 5.8904e-05
Epoch 2/10
 - 1087s - loss: 5.7236e-05 - val_loss: 5.6345e-05
Epoch 3/10
 - 1087s - loss: 5.6704e-05 - val_loss: 5.6370e-05
Epoch 4/10
 - 1088s - loss: 5.6448e-05 - val_loss: 5.5873e-05
Epoch 5/10
 - 1087s - loss: 5.6320e-05 - val_loss: 5.5674e-05
Epoch 6/10
 - 1087s - loss: 5.6302e-05 - val_loss: 5.6138e-05
Epoch 7/10
 - 1088s - loss: 5.6278e-05 - val_loss: 5.5765e-05
Epoch 8/10
 - 1087s - loss: 5.6261e-05 - val_loss: 5.6144e-05
Epoch 9/10
 - 1088s - loss: 5.6270e-05 - val_loss: 5.5861e-05
Epoch 10/10
 - 1088s - loss: 5.6266e-05 - val_loss: 5.5731e-05
unet lr = 0.0001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 256, 256, 32) 320         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 256, 256, 32) 128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_11[0][0]     
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 256, 256, 32) 128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_15[0][0]     
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_18[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 128, 128, 192 0           batch_normalization_14[0][0]     
                                                                 up_sampling2d_5[0][0]            
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 128, 128, 192 768         concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 128, 64) 110656      batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_19[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_20[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_12[0][0]     
                                                                 up_sampling2d_6[0][0]            
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_21[0][0]                  
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 256, 256, 1)  33          conv2d_22[0][0]                  
==================================================================================================
Total params: 473,537
Trainable params: 472,257
Non-trainable params: 1,280
__________________________________________________________________________________________________
10 32 0.0001
Epoch 1/10
 - 1471s - loss: 8.3736e-05 - val_loss: 4.9781e-05
Epoch 2/10
 - 1466s - loss: 4.9282e-05 - val_loss: 4.8416e-05
Epoch 3/10
 - 1465s - loss: 4.8555e-05 - val_loss: 4.8080e-05
Epoch 4/10
 - 1465s - loss: 4.8230e-05 - val_loss: 4.7657e-05
Epoch 5/10
 - 1465s - loss: 4.8092e-05 - val_loss: 4.7461e-05
Epoch 6/10
 - 1465s - loss: 4.8074e-05 - val_loss: 4.7974e-05
Epoch 7/10
 - 1465s - loss: 4.8048e-05 - val_loss: 4.7906e-05
Epoch 8/10
 - 1465s - loss: 4.8036e-05 - val_loss: 4.9220e-05
Epoch 9/10
 - 1465s - loss: 4.8034e-05 - val_loss: 4.8926e-05
Epoch 10/10
 - 1465s - loss: 4.8029e-05 - val_loss: 5.7899e-05
Epoch 1/10
unet lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 256, 256, 32) 320         input_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 256, 256, 32) 128         conv2d_24[0][0]                  
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_19[0][0]     
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 256, 256, 32) 128         conv2d_25[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 128, 128, 64) 256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_21[0][0]     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 128, 128, 64) 256         conv2d_27[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 64, 64, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_28[0][0]                  
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_23[0][0]     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 64, 64, 128)  512         conv2d_29[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 128, 192 0           batch_normalization_22[0][0]     
                                                                 up_sampling2d_7[0][0]            
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 128, 128, 192 768         concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 128, 128, 64) 110656      batch_normalization_25[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_30[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_31[0][0]                  
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 256, 256, 96) 0           batch_normalization_20[0][0]     
                                                                 up_sampling2d_8[0][0]            
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_8[0][0]              
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_32[0][0]                  
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 256, 256, 1)  33          conv2d_33[0][0]                  
==================================================================================================
Total params: 473,537
Trainable params: 472,257
Non-trainable params: 1,280
__________________________________________________________________________________________________
10 32 1e-05
Epoch 1/10
 - 1480s - loss: 2.8989e-04 - val_loss: 5.4325e-05
Epoch 2/10
 - 1475s - loss: 5.0305e-05 - val_loss: 4.9097e-05
Epoch 3/10
 - 1474s - loss: 4.9181e-05 - val_loss: 4.8975e-05
Epoch 4/10
 - 1475s - loss: 4.8847e-05 - val_loss: 4.8223e-05
Epoch 5/10
 - 1475s - loss: 4.8701e-05 - val_loss: 4.8018e-05
Epoch 6/10
 - 1474s - loss: 4.8677e-05 - val_loss: 4.8515e-05
Epoch 7/10
 - 1475s - loss: 4.8641e-05 - val_loss: 4.8100e-05
Epoch 8/10
 - 1475s - loss: 4.8616e-05 - val_loss: 4.8463e-05
Epoch 9/10
 - 1474s - loss: 4.8616e-05 - val_loss: 4.8221e-05
Epoch 10/10
 - 1475s - loss: 4.8609e-05 - val_loss: 4.8018e-05
unet_simple_deep lr = 0.0001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 256, 256, 32) 320         input_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 256, 256, 32) 128         conv2d_35[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 128, 128, 32) 0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 128, 128, 64) 256         conv2d_36[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 64, 64, 64)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 64, 64, 128)  512         conv2d_37[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 32, 32, 128)  0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 32, 32, 128)  147584      average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 32, 32, 128)  512         conv2d_38[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_29[0][0]     
                                                                 up_sampling2d_9[0][0]            
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 64, 64, 256)  1024        concatenate_9[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 64, 64, 64)   147520      batch_normalization_31[0][0]     
__________________________________________________________________________________________________
up_sampling2d_10 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_39[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 128, 128, 128 0           batch_normalization_28[0][0]     
                                                                 up_sampling2d_10[0][0]           
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 128, 128, 128 512         concatenate_10[0][0]             
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 128, 128, 64) 73792       batch_normalization_32[0][0]     
__________________________________________________________________________________________________
up_sampling2d_11 (UpSampling2D) (None, 256, 256, 64) 0           conv2d_40[0][0]                  
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 256, 256, 96) 0           batch_normalization_27[0][0]     
                                                                 up_sampling2d_11[0][0]           
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 256, 256, 96) 384         concatenate_11[0][0]             
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 256, 256, 32) 27680       batch_normalization_33[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 256, 256, 1)  33          conv2d_41[0][0]                  
==================================================================================================
Total params: 492,609
Trainable params: 490,945
Non-trainable params: 1,664
__________________________________________________________________________________________________
10 32 0.0001
Epoch 1/10
 - 1105s - loss: 2.3137e-04 - val_loss: 5.7884e-05
Epoch 2/10
 - 1103s - loss: 5.8187e-05 - val_loss: 5.6336e-05
Epoch 3/10
 - 1102s - loss: 5.7581e-05 - val_loss: 5.6273e-05
Epoch 4/10
 - 1102s - loss: 5.7128e-05 - val_loss: 5.5949e-05
Epoch 5/10
 - 1103s - loss: 5.6862e-05 - val_loss: 5.7155e-05
Epoch 6/10
 - 1102s - loss: 5.6744e-05 - val_loss: 5.6762e-05
Epoch 7/10
 - 1103s - loss: 5.6615e-05 - val_loss: 5.9723e-05
Epoch 8/10
 - 1102s - loss: 5.6518e-05 - val_loss: 5.6088e-05
Epoch 9/10
 - 1101s - loss: 5.6467e-05 - val_loss: 5.6224e-05
Epoch 10/10
 - 1103s - loss: 5.6420e-05 - val_loss: 5.6707e-05
Epoch 1/10
unet_simple_deep lr = 1e-05
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 256, 256, 32) 320         input_6[0][0]                    
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 256, 256, 32) 128         conv2d_43[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 128, 128, 32) 0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 128, 128, 64) 18496       average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 128, 128, 64) 256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 64, 64, 64)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 64, 64, 128)  73856       average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 64, 64, 128)  512         conv2d_45[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 32, 32, 128)  0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 32, 32, 128)  147584      average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 32, 32, 128)  512         conv2d_46[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_12 (UpSampling2D) (None, 64, 64, 128)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 64, 64, 256)  0           batch_normalization_36[0][0]     
                                                                 up_sampling2d_12[0][0]           
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 64, 64, 256)  1024        concatenate_12[0][0]             
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 64, 64, 64)   147520      batch_normalization_38[0][0]     
__________________________________________________________________________________________________
up_sampling2d_13 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_47[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 128, 128, 128 0           batch_normalization_35[0][0]     
                                                                 up_sampling2d_13[0][0]           
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 128, 128, 128 512         concatenate_13[0][0]             
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 128, 128, 64) 73792       batch_normalization_39[0][0]     
__________________________________________________________________________________________________
up_sampling2d_14 (UpSampling2D) (None, 256, 256, 64) 0           conv2d_48[0][0]                  
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 256, 256, 96) 0           batch_normalization_34[0][0]     
                                                                 up_sampling2d_14[0][0]           
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 256, 256, 96) 384         concatenate_14[0][0]             
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 256, 256, 32) 27680       batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 256, 256, 1)  33          conv2d_49[0][0]                  
==================================================================================================
Total params: 492,609
Trainable params: 490,945
Non-trainable params: 1,664
__________________________________________________________________________________________________
10 32 1e-05
Epoch 1/10
 - 1116s - loss: 0.0035 - val_loss: 0.0020
Epoch 2/10
 - 1112s - loss: 7.6351e-04 - val_loss: 4.9515e-05
Epoch 3/10
 - 1113s - loss: 4.9309e-05 - val_loss: 4.8823e-05
Epoch 4/10
 - 1113s - loss: 4.8908e-05 - val_loss: 4.8315e-05
Epoch 5/10
 - 1113s - loss: 4.8734e-05 - val_loss: 4.8144e-05
Epoch 6/10
 - 1112s - loss: 4.8686e-05 - val_loss: 4.8587e-05
Epoch 7/10
 - 1113s - loss: 4.8636e-05 - val_loss: 4.8152e-05
Epoch 8/10
 - 1113s - loss: 4.8593e-05 - val_loss: 4.8494e-05
Epoch 9/10
 - 1113s - loss: 4.8578e-05 - val_loss: 4.8098e-05
Epoch 10/10
 - 1112s - loss: 4.8554e-05 - val_loss: 4.7952e-05
